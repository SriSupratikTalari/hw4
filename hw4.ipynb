{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ceeeb46",
   "metadata": {
    "id": "0ceeeb46"
   },
   "source": [
    "# Homework 4\n",
    "\n",
    "For this assignment, you will be developing an artificial neural network to classify data given in the __[Dry Beans Data Set](https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset#)__. This data set was obtained as a part of a research study by Selcuk University, Turkey, in which a computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features. More details on the study can be found in the following __[research paper](https://www.sciencedirect.com/science/article/pii/S0168169919311573)__. <br>\n",
    "### **Make sure to use the lecture notebook on an introduction to keras and cross validation located [here](https://colab.research.google.com/drive/1ksEGL7SJ_wutCIyPYx7Loe5EPdOij6dJ?usp=sharing) and [here](https://colab.research.google.com/drive/1C9Mwf1J2ril1Q4l6n2BjQMb8YaFySG5_?usp=sharing)**.\n",
    "\n",
    "## About the Data Set\n",
    "Seven different types of dry beans were used in a study in Selcuk University, Turkey, taking into account the features such as form, shape, type, and structure by the market situation. A computer vision system was developed to distinguish seven different registered varieties of dry beans with similar features in order to obtain uniform seed classification. For the **classification** model, images of 13611 grains of 7 different registered dry beans were taken with a high-resolution camera. Bean images obtained by computer vision system were subjected to segmentation and feature extraction stages, and a total of 16 features - 12 dimensions and 4 shape forms - were obtained from the grains.\n",
    "\n",
    "Number of Instances (records in the data set): __13611__\n",
    "\n",
    "Number of Attributes (fields within each record, including the class): __17__\n",
    "\n",
    "### Data Set Attribute Information:\n",
    "\n",
    "1. __Area (A)__ : The area of a bean zone and the number of pixels within its boundaries.\n",
    "2. __Perimeter (P)__ : Bean circumference is defined as the length of its border.\n",
    "3. __Major axis length (L)__ : The distance between the ends of the longest line that can be drawn from a bean.\n",
    "4. __Minor axis length (l)__ : The longest line that can be drawn from the bean while standing perpendicular to the main axis.\n",
    "5. __Aspect ratio (K)__ : Defines the relationship between L and l.\n",
    "6. __Eccentricity (Ec)__ : Eccentricity of the ellipse having the same moments as the region.\n",
    "7. __Convex area (C)__ : Number of pixels in the smallest convex polygon that can contain the area of a bean seed.\n",
    "8. __Equivalent diameter (Ed)__ : The diameter of a circle having the same area as a bean seed area.\n",
    "9. __Extent (Ex)__ : The ratio of the pixels in the bounding box to the bean area.\n",
    "10. __Solidity (S)__ : Also known as convexity. The ratio of the pixels in the convex shell to those found in beans.\n",
    "11. __Roundness (R)__ : Calculated with the following formula: (4piA)/(P^2)\n",
    "12. __Compactness (CO)__ : Measures the roundness of an object: Ed/L\n",
    "13. __ShapeFactor1 (SF1)__\n",
    "14. __ShapeFactor2 (SF2)__\n",
    "15. __ShapeFactor3 (SF3)__\n",
    "16. __ShapeFactor4 (SF4)__\n",
    "\n",
    "17. __Classes : *Seker, Barbunya, Bombay, Cali, Dermosan, Horoz, Sira*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61beac74",
   "metadata": {
    "id": "61beac74"
   },
   "source": [
    "### Libraries that can be used :\n",
    "- NumPy, SciPy, Pandas, Sci-Kit Learn, TensorFlow, Keras. You may also use PyTorch (though support may be limited)\n",
    "- Any other library used during the lectures and discussion sessions.\n",
    "\n",
    "### Other Notes\n",
    "- Don't worry about not being able to achieve high accuracy, it is neither the goal nor the grading standard of this assignment.\n",
    "- Discussion and Lecture materials should be helpful for doing the assignments.\n",
    "- The homework submission should be a .ipynb file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "LcVrrFbn1wzE",
   "metadata": {
    "id": "LcVrrFbn1wzE"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ucsd-cse151a-ss25/hw4.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264c751",
   "metadata": {
    "id": "0264c751"
   },
   "source": [
    "\n",
    "## Exercise 1 : Building a Feed-Forward Neural Network(50 points)\n",
    "\n",
    "### Exercise 1.1 : Data Preprocessing (10 points)\n",
    "\n",
    "- As the classes are categorical, use one-hot encoding to represent the set of classes. You will find this useful when developing the output layer of the neural network.\n",
    "- Split the data into training and testing set by __90:10__ and use the training set for training the model and the test set to evaluate the model performance. Please set verbose=0 to suppress output during training.\n",
    "- Normalize each field of the input data using the min-max normalization technique.\n",
    "\n",
    "__Notes:__\n",
    "\n",
    "- Splitting of the dataset should be done __before__ the normalization step and __after__ the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1St-29dI04l3",
   "metadata": {
    "id": "1St-29dI04l3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8da01a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Dry_Beans_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97aa0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d7aed51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44830</td>\n",
       "      <td>814.955</td>\n",
       "      <td>320.731947</td>\n",
       "      <td>178.405838</td>\n",
       "      <td>1.797766</td>\n",
       "      <td>0.831018</td>\n",
       "      <td>45297</td>\n",
       "      <td>238.912806</td>\n",
       "      <td>0.658877</td>\n",
       "      <td>0.989690</td>\n",
       "      <td>0.848226</td>\n",
       "      <td>0.744899</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.554874</td>\n",
       "      <td>0.997534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33476</td>\n",
       "      <td>691.826</td>\n",
       "      <td>258.837971</td>\n",
       "      <td>165.220760</td>\n",
       "      <td>1.566619</td>\n",
       "      <td>0.769773</td>\n",
       "      <td>33907</td>\n",
       "      <td>206.453305</td>\n",
       "      <td>0.721155</td>\n",
       "      <td>0.987289</td>\n",
       "      <td>0.878921</td>\n",
       "      <td>0.797616</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.636191</td>\n",
       "      <td>0.996669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27057</td>\n",
       "      <td>606.138</td>\n",
       "      <td>227.460904</td>\n",
       "      <td>151.860320</td>\n",
       "      <td>1.497830</td>\n",
       "      <td>0.744491</td>\n",
       "      <td>27358</td>\n",
       "      <td>185.607226</td>\n",
       "      <td>0.801831</td>\n",
       "      <td>0.988998</td>\n",
       "      <td>0.925436</td>\n",
       "      <td>0.815996</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.665850</td>\n",
       "      <td>0.997330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49483</td>\n",
       "      <td>844.283</td>\n",
       "      <td>326.602913</td>\n",
       "      <td>194.689529</td>\n",
       "      <td>1.677558</td>\n",
       "      <td>0.802907</td>\n",
       "      <td>50289</td>\n",
       "      <td>251.005403</td>\n",
       "      <td>0.680179</td>\n",
       "      <td>0.983973</td>\n",
       "      <td>0.872348</td>\n",
       "      <td>0.768534</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.590644</td>\n",
       "      <td>0.990840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22461</td>\n",
       "      <td>544.584</td>\n",
       "      <td>192.801303</td>\n",
       "      <td>148.541136</td>\n",
       "      <td>1.297966</td>\n",
       "      <td>0.637517</td>\n",
       "      <td>22699</td>\n",
       "      <td>169.110122</td>\n",
       "      <td>0.774731</td>\n",
       "      <td>0.989515</td>\n",
       "      <td>0.951720</td>\n",
       "      <td>0.877121</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.769342</td>\n",
       "      <td>0.998579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13606</th>\n",
       "      <td>39956</td>\n",
       "      <td>745.166</td>\n",
       "      <td>273.867402</td>\n",
       "      <td>186.564001</td>\n",
       "      <td>1.467954</td>\n",
       "      <td>0.732079</td>\n",
       "      <td>40504</td>\n",
       "      <td>225.551678</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.986470</td>\n",
       "      <td>0.904244</td>\n",
       "      <td>0.823580</td>\n",
       "      <td>0.006854</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.678284</td>\n",
       "      <td>0.995690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>171914</td>\n",
       "      <td>1595.676</td>\n",
       "      <td>598.541646</td>\n",
       "      <td>368.358372</td>\n",
       "      <td>1.624889</td>\n",
       "      <td>0.788194</td>\n",
       "      <td>174673</td>\n",
       "      <td>467.854361</td>\n",
       "      <td>0.815980</td>\n",
       "      <td>0.984205</td>\n",
       "      <td>0.848461</td>\n",
       "      <td>0.781657</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.610988</td>\n",
       "      <td>0.992788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>48266</td>\n",
       "      <td>817.340</td>\n",
       "      <td>304.682706</td>\n",
       "      <td>202.282198</td>\n",
       "      <td>1.506226</td>\n",
       "      <td>0.747812</td>\n",
       "      <td>48780</td>\n",
       "      <td>247.899536</td>\n",
       "      <td>0.807232</td>\n",
       "      <td>0.989463</td>\n",
       "      <td>0.907916</td>\n",
       "      <td>0.813632</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.661997</td>\n",
       "      <td>0.997117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>43279</td>\n",
       "      <td>843.066</td>\n",
       "      <td>336.280446</td>\n",
       "      <td>164.667135</td>\n",
       "      <td>2.042183</td>\n",
       "      <td>0.871907</td>\n",
       "      <td>43813</td>\n",
       "      <td>234.743550</td>\n",
       "      <td>0.614566</td>\n",
       "      <td>0.987812</td>\n",
       "      <td>0.765181</td>\n",
       "      <td>0.698059</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.487286</td>\n",
       "      <td>0.995128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>46856</td>\n",
       "      <td>809.173</td>\n",
       "      <td>302.595376</td>\n",
       "      <td>197.920303</td>\n",
       "      <td>1.528875</td>\n",
       "      <td>0.756429</td>\n",
       "      <td>47372</td>\n",
       "      <td>244.251739</td>\n",
       "      <td>0.726900</td>\n",
       "      <td>0.989107</td>\n",
       "      <td>0.899275</td>\n",
       "      <td>0.807189</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.651555</td>\n",
       "      <td>0.996145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13611 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0       44830    814.955       320.731947       178.405838      1.797766   \n",
       "1       33476    691.826       258.837971       165.220760      1.566619   \n",
       "2       27057    606.138       227.460904       151.860320      1.497830   \n",
       "3       49483    844.283       326.602913       194.689529      1.677558   \n",
       "4       22461    544.584       192.801303       148.541136      1.297966   \n",
       "...       ...        ...              ...              ...           ...   \n",
       "13606   39956    745.166       273.867402       186.564001      1.467954   \n",
       "13607  171914   1595.676       598.541646       368.358372      1.624889   \n",
       "13608   48266    817.340       304.682706       202.282198      1.506226   \n",
       "13609   43279    843.066       336.280446       164.667135      2.042183   \n",
       "13610   46856    809.173       302.595376       197.920303      1.528875   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0          0.831018       45297     238.912806  0.658877  0.989690   0.848226   \n",
       "1          0.769773       33907     206.453305  0.721155  0.987289   0.878921   \n",
       "2          0.744491       27358     185.607226  0.801831  0.988998   0.925436   \n",
       "3          0.802907       50289     251.005403  0.680179  0.983973   0.872348   \n",
       "4          0.637517       22699     169.110122  0.774731  0.989515   0.951720   \n",
       "...             ...         ...            ...       ...       ...        ...   \n",
       "13606      0.732079       40504     225.551678  0.796000  0.986470   0.904244   \n",
       "13607      0.788194      174673     467.854361  0.815980  0.984205   0.848461   \n",
       "13608      0.747812       48780     247.899536  0.807232  0.989463   0.907916   \n",
       "13609      0.871907       43813     234.743550  0.614566  0.987812   0.765181   \n",
       "13610      0.756429       47372     244.251739  0.726900  0.989107   0.899275   \n",
       "\n",
       "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
       "0         0.744899      0.007154      0.001359      0.554874      0.997534  \n",
       "1         0.797616      0.007732      0.001930      0.636191      0.996669  \n",
       "2         0.815996      0.008407      0.002299      0.665850      0.997330  \n",
       "3         0.768534      0.006600      0.001420      0.590644      0.990840  \n",
       "4         0.877121      0.008584      0.003134      0.769342      0.998579  \n",
       "...            ...           ...           ...           ...           ...  \n",
       "13606     0.823580      0.006854      0.001945      0.678284      0.995690  \n",
       "13607     0.781657      0.003482      0.000802      0.610988      0.992788  \n",
       "13608     0.813632      0.006313      0.001706      0.661997      0.997117  \n",
       "13609     0.698059      0.007770      0.001138      0.487286      0.995128  \n",
       "13610     0.807189      0.006458      0.001691      0.651555      0.996145  \n",
       "\n",
       "[13611 rows x 16 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60a48346",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot=OneHotEncoder(sparse_output=False).fit_transform(df[['Class']])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, hot, test_size=0.10, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1dff4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train) \n",
    "X_test_norm  = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a343ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "o4QPlcYa0sHN",
   "metadata": {
    "id": "o4QPlcYa0sHN"
   },
   "source": [
    "### Exercise 1.2 : Training and Testing the Neural Network (40 points)\n",
    "\n",
    "Design a 3-layer (3 hidden layers and this does not include the input or output layer) artificial deep neural network, specifically a feed-forward multi-layer perceptron (using the sigmoid activation function), to classify the type of 'Dry Bean' given the other attributes in the data set, similar to the one mentioned in the paper above. Please note that this is a **multi-class classification** problem so select the right number of nodes accordingly for the input and output layers.\n",
    "\n",
    "Consider the following hyperparameters while developing your model:\n",
    "\n",
    "- Model type: Keras Sequential\n",
    "- Make sure your input layer matches the size of your X matrix\n",
    "- Number and type of hidden layers: 3 and Dense\n",
    "- Number of nodes in each hidden layer: 12\n",
    "- Learning rate should be 0.3\n",
    "- Number of epochs should be 100\n",
    "- The sigmoid function is to be used as the activation function in each layer\n",
    "- Your output layer has to use a sigmoid function and the number of outputs should match the shape of your y\n",
    "- Your loss function should be MSE\n",
    "- Stochastic Gradient Descent should be used to minimize the error rate\n",
    "\n",
    "**Note:** We are having you use MSE as your loss function for this model, is this a good choice? Why or why not? If not, what should you use instead in future models? Answer below\n",
    "\n",
    "__Requirements once the model has been trained :__\n",
    "\n",
    "- A confusion matrix for all classes, specifying the true positive, true negative, false positive, and false negative cases for each category in the class\n",
    "- Since we do have OHE output (multi-class output) you will need to either reshape or argmax your outputs. Make sure they have already been thresholded as well i.e. look at yhat and do you see 1's and 0's?\n",
    "- The accuracy and mean squared error (MSE) of the model\n",
    "- The precision and recall for each label in the class\n",
    "\n",
    "__Notes :__\n",
    "\n",
    "- The mean squared error (MSE) values obtained __should be positive__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "223e98b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/srisupratiktalari/Library/Python/3.12/lib/python/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/srisupratiktalari/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/srisupratiktalari/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "KhW7lew706U8",
   "metadata": {
    "id": "KhW7lew706U8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fda50e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1e88e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X_train_norm.shape[1],)),\n",
    "    Dense(12, activation=\"sigmoid\"),\n",
    "    Dense(12, activation=\"sigmoid\"),\n",
    "    Dense(12, activation=\"sigmoid\"),\n",
    "    Dense(y_train.shape[1], activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4964a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SGD(learning_rate=0.3)\n",
    "model.compile(optimizer=a, loss=\"mse\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e03ca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = model.fit(\n",
    "    X_train_norm, y_train,\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    validation_data=(X_test_norm, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8563ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test_norm) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "324a25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(model.predict(X_test_norm), axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2089c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2b689fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.50      0.53       137\n",
      "           1       0.00      0.00      0.00        63\n",
      "           2       0.73      0.93      0.82       195\n",
      "           3       0.83      0.97      0.89       342\n",
      "           4       0.83      0.98      0.90       181\n",
      "           5       0.91      0.95      0.93       200\n",
      "           6       0.88      0.60      0.71       244\n",
      "\n",
      "    accuracy                           0.80      1362\n",
      "   macro avg       0.68      0.70      0.68      1362\n",
      "weighted avg       0.77      0.80      0.78      1362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e246d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3757c652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1651982378854626"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true_classes, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "42237777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8039647577092511"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true_classes,y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0334c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 68   0  54   0   3   2  10]\n",
      " [ 49   0  14   0   0   0   0]\n",
      " [  5   0 181   0   7   1   1]\n",
      " [  0   0   0 331   0   7   4]\n",
      " [  0   0   0   2 178   0   1]\n",
      " [  0   0   0   5   0 191   4]\n",
      " [  0   0   0  63  27   8 146]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f5188",
   "metadata": {
    "id": "083f5188"
   },
   "source": [
    "## Exercise 2 : k-fold Cross Validation (20 points)\n",
    "\n",
    "In order to avoid **using biased models**, use 10-fold cross validation to generalize the model from Ex1.2 on the given data set. You can choose a n_repeats value of 1-5\n",
    "\n",
    "__Requirements :__\n",
    "- Print the accuracy values during each iteration of the **cross validation** not the iterations per epoch or the epochs\n",
    "- Print the overall average accuracy per each n_fold value, look at the documentation for the scoring parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "tu8rIov607s4",
   "metadata": {
    "id": "tu8rIov607s4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aceb726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4c4b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5b63900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim):\n",
    "    model = Sequential([\n",
    "        Dense(12, activation=\"sigmoid\", input_dim=input_dim),\n",
    "        Dense(12, activation=\"sigmoid\"),\n",
    "        Dense(12, activation=\"sigmoid\"),\n",
    "        Dense(output_dim, activation=\"sigmoid\")\n",
    "    ])\n",
    "    optimizer = SGD(learning_rate=0.3)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63e8aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KerasClassifier(\n",
    "    model=create_model,\n",
    "    model__input_dim=X_train_norm.shape[1],\n",
    "    model__output_dim=y_train.shape[1],\n",
    "    epochs=100,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scikeras scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "193cc08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.6686\n",
      "Training fold 2...\n",
      "Fold 2 Accuracy: 0.4694\n",
      "Training fold 3...\n",
      "Fold 3 Accuracy: 0.5673\n",
      "Training fold 4...\n",
      "Fold 4 Accuracy: 0.5029\n",
      "Training fold 5...\n",
      "Fold 5 Accuracy: 0.5437\n",
      "Training fold 6...\n",
      "Fold 6 Accuracy: 0.5845\n",
      "Training fold 7...\n",
      "Fold 7 Accuracy: 0.5820\n",
      "Training fold 8...\n",
      "Fold 8 Accuracy: 0.5788\n",
      "Training fold 9...\n",
      "Fold 9 Accuracy: 0.7437\n",
      "Training fold 10...\n",
      "Fold 10 Accuracy: 0.5825\n",
      "\n",
      "Average Accuracy across 10 folds: 0.5823332607746124\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):    \n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    fold_accuracies = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_norm), 1):\n",
    "        print(f\"Training fold {fold}...\")\n",
    "        X_tr, X_val = X_train_norm[train_idx], X_train_norm[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        model = create_model(X_train_norm.shape[1], y_train.shape[1])\n",
    "        history = model.fit(X_tr, y_tr, epochs=100, verbose=0)\n",
    "        loss, acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "        fold_accuracies.append(acc)\n",
    "        print(f\"Fold {fold} Accuracy: {acc:.4f}\")\n",
    "    print(\"\\nAverage Accuracy across 10 folds:\", np.mean(fold_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef874c5",
   "metadata": {
    "id": "cef874c5"
   },
   "source": [
    "## Exercise 3 : Hyperparameter Tuning (25 points)\n",
    "\n",
    "Use either grid search or random search methodology to find the optimal number of nodes required in each hidden layer, as well as the optimal learning rate and the different activation functions or optimization approaches, [keras_tuner examples](https://keras.io/guides/keras_tuner/getting_started/) such that the accuracy of the model is maximum for the given data set.\n",
    "\n",
    "__Requirements :__\n",
    "- The set of optimal hyperparameters\n",
    "- Try your best to maximize accuracy using this set of optimal hyperparameters\n",
    "\n",
    "__Note :__ Hyperparameter tuning takes a lot of time to execute. Make sure that you choose the appropriate number of each hyperparameter (preferably 3 of each), and that you allocate enough time to execute your code. Make sure to tune at least three parameters with three options each at a minimum, but feel free to experiment with more, just recognize that it will grow exponentially in running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "32b74ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras-tuner) (3.11.3)\n",
      "Requirement already satisfied: packaging in /Users/srisupratiktalari/Library/Python/3.12/lib/python/site-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras-tuner) (2.32.4)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras->keras-tuner) (2.3.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras->keras-tuner) (2.1.3)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras->keras-tuner) (14.1.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras->keras-tuner) (0.1.0)\n",
      "Requirement already satisfied: h5py in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras->keras-tuner) (3.14.0)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras->keras-tuner) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras->keras-tuner) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->keras-tuner) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->keras-tuner) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->keras-tuner) (2025.7.14)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from optree->keras->keras-tuner) (4.14.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras->keras-tuner) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/srisupratiktalari/Library/Python/3.12/lib/python/site-packages (from rich->keras->keras-tuner) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572c87d",
   "metadata": {
    "id": "5572c87d"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(\n",
    "        units=hp.Choice(\"units_layer1\", [1, 3, 4]),\n",
    "        activation=hp.Choice(\"activation\", [\"sigmoid\", \"relu\", \"tanh\"]),\n",
    "        input_dim=X_train_norm.shape[1]\n",
    "    ))\n",
    "    for i in range(2, 4):\n",
    "        model.add(Dense(\n",
    "            units=hp.Choice(f\"units_layer{i}\", [1, 3, 2]),\n",
    "            activation=hp.Choice(\"activation\", [\"sigmoid\", \"relu\", \"tanh\"])\n",
    "        ))\n",
    "    model.add(Dense(y_train.shape[1], activation=\"softmax\"))\n",
    "    learning_rate = hp.Choice(\"learning_rate\", [0.01, 0.1, 0.3])\n",
    "    optimizer_choice = hp.Choice(\"optimizer\", [\"sgd\", \"adam\"])\n",
    "    if optimizer_choice == \"sgd\":\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d43a7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=2,        \n",
    "    executions_per_trial=1,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"drybean_tuning\"\n",
    ")\n",
    "\n",
    "tuner.search(X_train_norm, y_train, epochs=50, validation_data=(X_test_norm, y_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1ed05823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "Layer 1 units: 3\n",
      "Layer 2 units: 3\n",
      "Layer 3 units: 3\n",
      "Activation: tanh\n",
      "Optimizer: adam\n",
      "Learning rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(\"Layer 1 units:\", best_hp.get(\"units_layer1\"))\n",
    "print(\"Layer 2 units:\", best_hp.get(\"units_layer2\"))\n",
    "print(\"Layer 3 units:\", best_hp.get(\"units_layer3\"))\n",
    "print(\"Activation:\", best_hp.get(\"activation\"))\n",
    "print(\"Optimizer:\", best_hp.get(\"optimizer\"))\n",
    "print(\"Learning rate:\", best_hp.get(\"learning_rate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e224785a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with best hyperparameters: 0.8935388922691345\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "history = best_model.fit(X_train_norm, y_train, epochs=100, validation_data=(X_test_norm, y_test), verbose=0)\n",
    "\n",
    "loss, acc = best_model.evaluate(X_test_norm, y_test, verbose=0)\n",
    "print(\"Test Accuracy with best hyperparameters:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nPfZ4mzk09EI",
   "metadata": {
    "id": "nPfZ4mzk09EI"
   },
   "source": [
    "## Exercise 4 - Collaborative Statement (5 points)\n",
    "\n",
    "It is mandatory to include a Statement of Collaboration in each submission, that follows the guidelines below.\n",
    "Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed.\n",
    "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
    "programming assignments in particular, I encourage students to organize (perhaps using Piazza) to discuss the\n",
    "task descriptions, requirements, possible bugs in the support code, and the relevant technical content before they\n",
    "start working on it. However, you should not discuss the specific solutions, and as a guiding principle, you are\n",
    "not allowed to take anything written or drawn away from these discussions (no photographs of the blackboard,\n",
    "written notes, referring to Piazza, etc.). Especially after you have started working on the assignment, try to restrict\n",
    "the discussion to Piazza as much as possible, so that there is no doubt as to the extent of your collaboration.\n",
    "\n",
    "Even if you did not use any outside resources or collaborate with anyone, please state that explicitly in the space below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ebb6bf",
   "metadata": {},
   "source": [
    "contributers= Zack Roland, Hungjun Doh, Gui \n",
    "Chatgpt: chatgpt was used throughout this enitre notebook to help me with how to implement the imports and models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eef82d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
